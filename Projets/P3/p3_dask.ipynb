{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Initialisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librairies pour le traitement des données\n",
    "import pandas as pd\n",
    "# Dask API is a parallelized version of Numpy, Pandas, Sklearn.\n",
    "import dask.dataframe as dd #  Pour la première fois installer avec la commande 'pip install \"dask[complete]\"'\n",
    "import numpy as np\n",
    "\n",
    "# Librairies pour la visualisation de graphiques\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set() #Définir le style par défaut pour les graphiques\n",
    "\n",
    "\n",
    "# Librairies pour la visualisation de cartes\n",
    "import folium # Pour la première fois installer avec la commande 'pip install folium' ou 'conda install folium -c conda-forge'. Voir : https://python-visualization.github.io/folium/quickstart.html\n",
    "import branca.colormap as cm\n",
    "from branca.element import Template, MacroElement\n",
    "\n",
    "low_memory=False # faible mémoire vive (RAM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Définition de fonctions utilitaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verifier_taille(data, dask=True):\n",
    "    \"\"\" Fonction de vérification de la taille d'un data set \"\"\"\n",
    "    lignes = data.shape[0]\n",
    "    if dask:\n",
    "        lignes = lignes.compute()\n",
    "    colonnes = data.shape[1]\n",
    "    print('Le data set contient :')\n",
    "    print('\\t-', lignes, 'lignes et', colonnes, 'colonnes.')\n",
    "\n",
    "    nb_null = data.isnull().sum().sum()\n",
    "    if dask:\n",
    "        nb_null = nb_null.compute()\n",
    "    taille = lignes*colonnes\n",
    "    taille_null = 100*nb_null/taille\n",
    "    taille_non_null = 100*(taille-nb_null)/taille\n",
    "    print('\\t-', nb_null, 'valeurs manquantes, ce qui représente', round(taille_null,2), '% du data set.')\n",
    "\n",
    "    # Afficher la répartition du taux de valeurs manquantes\n",
    "    nan_data = pd.DataFrame({'valeurs (%)': [''], 'non-null('+str(round(taille_non_null,2))+'%)': [taille_non_null], 'null('+str(round(taille_null,2))+'%)': [taille_null]})\n",
    "    nan_data.set_index('valeurs (%)').plot(kind='barh', stacked=True, color=['green', 'orange'], figsize=(8,2), fontsize=12)\n",
    "    plt.xlabel('%')\n",
    "\n",
    "def afficher_echantillon(data, n=0.00002):\n",
    "    \"\"\" Afficher un sous-échantillon aléatoire \"\"\"\n",
    "    print('Voici un sous-échantillon aléatoire :')\n",
    "    return data.sample(frac=n, random_state=np.random.seed())\n",
    "\n",
    "def valeurs_manquantes(data):\n",
    "    \"\"\" Retourner les valeurs manquantes d'un data frame/set \"\"\"\n",
    "    return data[data.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Récupération du Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ouverture du fichier CSV en téléchargement : \n",
    "df = dd.read_csv('fr.openfoodfacts.org.products.csv', sep='\\t', assume_missing=True, low_memory=low_memory, \n",
    "dtype={'allergens': 'object',\n",
    "       'allergens_fr': 'object',\n",
    "       'categories': 'object',\n",
    "       'categories_fr': 'object',\n",
    "       'categories_tags': 'object',\n",
    "       'cities': 'object',\n",
    "       'cities_tags': 'object',\n",
    "       'code': 'object',\n",
    "       'created_t': 'object',\n",
    "       'emb_codes': 'object',       \n",
    "       'emb_codes_tags': 'object',\n",
    "       'first_packaging_code_geo': 'object',\n",
    "       'generic_name': 'object',\n",
    "       'image_small_url': 'object',\n",
    "       'image_url': 'object',\n",
    "       'ingredients_from_palm_oil_tags': 'object',\n",
    "       'ingredients_that_may_be_from_palm_oil_tags': 'object',\n",
    "       'labels': 'object',\n",
    "       'labels_fr': 'object',\n",
    "       'labels_tags': 'object',\n",
    "       'last_modified_t': 'object',\n",
    "       'main_category': 'object',\n",
    "       'main_category_fr': 'object',\n",
    "       'manufacturing_places': 'object',\n",
    "       'manufacturing_places_tags': 'object',\n",
    "       'origins': 'object',\n",
    "       'origins_tags': 'object',\n",
    "       'packaging': 'object',\n",
    "       'packaging_tags': 'object',\n",
    "       'pnns_groups_1': 'object',\n",
    "       'pnns_groups_2': 'object',\n",
    "       'purchase_places': 'object',\n",
    "       'stores': 'object',\n",
    "       'traces': 'object',\n",
    "       'traces_fr': 'object',\n",
    "       'traces_tags': 'object',          \n",
    "       'created_datetime': 'object',\n",
    "       'last_modified_datetime': 'object',\n",
    "       }) #le fichier doit être placé dans le même répertoire que ce notebook\n",
    "\n",
    "if not low_memory:\n",
    "       df = df.persist() #Si assez de RAM dispo, cele permettera d'accéler les futurs traitements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure du data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape[0].compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().compute()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verifier_taille(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "afficher_echantillon(df).iloc[:,30:50].compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valeurs_manquantes(df).compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation des colonnes dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_t = ['created_t', 'last_modified_t']\n",
    "for date in dates_t:\n",
    "    df[date] = dd.to_datetime(df[date], unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['created_datetime', 'last_modified_datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "afficher_echantillon(df).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask = (df['created_t'].str.contains('\\D')).replace(np.nan, False)\n",
    "# df[mask].compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask = (df['code'].str.contains('\\D')).replace(np.nan, False)\n",
    "# df[mask].compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df[df['code'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask = (df['code'].isna()).replace(np.nan, False)\n",
    "# df[mask].compute()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
