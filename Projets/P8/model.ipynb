{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession    \n",
    "from pyspark.sql import Row\n",
    "from pyspark.ml.linalg import DenseVector\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import IndexToString, StringIndexer\n",
    "from pyspark.ml.classification import RandomForestClassifier, OneVsRest\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "production_mode = True\n",
    "local_mode = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext()\n",
    "spark = SparkSession(sc)\n",
    "\n",
    "origin_path = 'F:/' if local_mode else 's3a://dr.hadinono/OC/P8/'\n",
    "\n",
    "csv_path = origin_path+'fruits-360/CSV/'\n",
    "csv_dir = origin_path+'fruits-360/CSV/Separate/'\n",
    "csv_separate_dir = csv_dir+'Separate/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the images-csv file\n",
    "data = spark.read.options(delimiter=\";\", header=True,\n",
    "                        maxCharsPerColumn=-1).csv(csv_path+'data-reduced.csv')\n",
    "\n",
    "# Convert to vectors\n",
    "data = data.rdd.map(lambda row: Row(label=row.label, features=DenseVector([float(x) for x in row.features.strip('][').split(',')]))).toDF()\n",
    "if not production_mode:\n",
    "    data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index labels, adding metadata to the label column.\n",
    "# Fit on whole dataset to include all labels in index.\n",
    "labelIndexer = StringIndexer(inputCol=\"label\", outputCol=\"indexedLabel\").fit(data)\n",
    "\n",
    "if not production_mode:\n",
    "    data.show()\n",
    "\n",
    "# Split the data into training and test sets (30% held out for testing)\n",
    "(trainingData, testData) = data.randomSplit([0.6, 0.4])\n",
    "trainingData.persist()\n",
    "testData.persist()\n",
    "\n",
    "if not production_mode:\n",
    "    trainingData.show()\n",
    "    testData.show()\n",
    "\n",
    "# Train a RandomForest model.\n",
    "rf = RandomForestClassifier(labelCol=\"indexedLabel\", featuresCol=\"features\", numTrees=10)\n",
    "\n",
    "# Convert indexed labels back to original labels.\n",
    "labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\",\n",
    "                               labels=labelIndexer.labels)\n",
    "\n",
    "# Chain indexers and forest in a Pipeline\n",
    "pipeline = Pipeline(stages=[labelIndexer, rf, labelConverter])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------+--------------------+\n",
      "|predictedLabel|         label|            features|\n",
      "+--------------+--------------+--------------------+\n",
      "|Apple_Braeburn|Apple_Braeburn|[0.88212809953114...|\n",
      "+--------------+--------------+--------------------+\n",
      "\n",
      "Test accuracy = 1\n"
     ]
    }
   ],
   "source": [
    "# Train model.  This also runs the indexers.\n",
    "model = pipeline.fit(trainingData)\n",
    "\n",
    "# Make predictions.\n",
    "predictions = model.transform(testData)\n",
    "\n",
    "if not production_mode:\n",
    "    # Select example rows to display.\n",
    "    predictions.select(\"predictedLabel\", \"label\", \"features\").show()\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test accuracy = %g\" % (accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'label': predictions.select(\"label\").rdd.map(lambda x : x[0]).collect(), 'predictedLabel': predictions.select(\"predictedLabel\").rdd.map(lambda x : x[0]).collect(), 'features':predictions.select(\"features\").rdd.map(lambda x : x[0]).collect()})\n",
    "df.to_csv(csv_path+'Predictions-accuracy='+str(round(accuracy,2))+'.csv', index=False, sep=\";\" , quoting=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>> all done!\n"
     ]
    }
   ],
   "source": [
    "# Close Spark\n",
    "print('>>>>>>>> all done!')\n",
    "sc.stop()\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "22a000a366ddd64c4ddab40e3652306b9e13e369594fde0c1e9f1fab224351e6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
